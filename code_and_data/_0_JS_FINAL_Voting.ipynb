{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"_0_JS_FINAL_Voting.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_mBkJx5KMkC","outputId":"cd8b2211-821d-46ff-9966-cf6b4d7bcb46"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 26304 entries, 0 to 26303\n","Data columns (total 8 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   시간           26304 non-null  int64  \n"," 1   일조(hr)       26304 non-null  float64\n"," 2   일사(MJ/m2)    26304 non-null  float64\n"," 3   전운량(10분위)    26304 non-null  float64\n"," 4   중하층운량(10분위)  26304 non-null  float64\n"," 5   지면온도(°C)     26304 non-null  float64\n"," 6   시정(10m)      26304 non-null  int64  \n"," 7   전력거래량        26304 non-null  float64\n","dtypes: float64(6), int64(2)\n","memory usage: 1.6 MB\n","None\n","----------------------\n","시간               23.000000\n","일조(hr)            1.000000\n","일사(MJ/m2)         3.780000\n","전운량(10분위)        10.000000\n","중하층운량(10분위)      10.000000\n","지면온도(°C)         62.400000\n","시정(10m)        5000.000000\n","전력거래량            10.807822\n","dtype: float64\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","data = pd.read_csv('sun_and_cloud.csv',encoding='cp949')\n","# data.drop(columns=['지면온도(°C)','시정(10m)'],inplace=True)\n","\n","print(data.info())\n","print('----------------------')\n","print(data.max())"]},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","result = scaler.fit_transform(data)\n","df_scld= pd.DataFrame(data=result,columns=data.columns)"],"metadata":{"id":"YZ1PfYLBKWUR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train = df_scld.iloc[:25560,:-1] # 18년 ~ 20년 11월 : 25560 --> Train & Validation (24096 ==> 20년 10월 1일 00시)\n","y_train = df_scld.iloc[:25560,-1] # 18년 ~ 20년 11월 --> Train & Validation\n","\n","x_pred = df_scld.iloc[25560:,:-1] # 20년 12월- 예측용 변수 --> Preidction\n","y_pred = df_scld.iloc[25560:,-1] # 20년 12월 - 예측용 정답 --> Preidction\n","\n","\n","# --- Ensemble 을 위해서 np.array 형태로 data type 전환해보기\n","x_train = np.array(x_train)\n","y_train = np.array(y_train)\n","\n","x_pred = np.array(x_pred)\n","y_pred = np.array(y_pred)\n","\n","print(x_train,'\\n',x_pred,'\\n',y_train,'\\n',y_pred)\n","print('------------------------------------------------------------------------------------------------------------------------')\n","print(x_train.shape,'\\n',x_pred.shape,'\\n',y_train.shape,'\\n',y_pred.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xROQUNwtKixR","outputId":"e8d2bd9d-db2d-4dea-b4c7-682434a1e4ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.         0.         0.         ... 0.         0.15       0.26823388]\n"," [0.04347826 0.         0.         ... 0.         0.14342105 0.39722725]\n"," [0.08695652 0.         0.         ... 0.         0.13947368 0.39722725]\n"," ...\n"," [0.91304348 0.         0.         ... 0.         0.16973684 0.39722725]\n"," [0.95652174 0.         0.         ... 0.         0.16052632 0.39722725]\n"," [1.         0.         0.         ... 0.         0.15657895 0.39722725]] \n"," [[0.         0.         0.         ... 0.         0.15526316 0.39722725]\n"," [0.04347826 0.         0.         ... 0.         0.15394737 0.39722725]\n"," [0.08695652 0.         0.         ... 0.         0.15131579 0.39722725]\n"," ...\n"," [0.91304348 0.         0.         ... 0.         0.10394737 0.39722725]\n"," [0.95652174 0.         0.         ... 0.         0.09868421 0.39722725]\n"," [1.         0.         0.         ... 0.         0.09342105 0.39722725]] \n"," [0.         0.         0.         ... 0.00438201 0.         0.        ] \n"," [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 4.27051815e-03\n"," 1.28405242e-01 3.96698706e-01 6.28714648e-01 7.51850928e-01\n"," 7.73565386e-01 7.27539462e-01 5.12777413e-01 1.64768628e-01\n"," 4.04024974e-02 2.25947467e-04 5.27765909e-03 5.47011229e-03\n"," 5.47011229e-03 2.54630396e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.97859994e-04\n"," 3.09232517e-02 8.55873644e-02 1.56740646e-01 2.78634955e-01\n"," 4.11856616e-01 4.22719120e-01 4.04531736e-01 3.16269642e-01\n"," 7.00828530e-02 1.19913152e-04 5.28506113e-03 4.63368105e-03\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.86551722e-03\n"," 1.11553373e-01 3.73344972e-01 6.17274877e-01 7.45236644e-01\n"," 7.88874576e-01 7.44375971e-01 6.20099498e-01 3.58386546e-01\n"," 7.31044608e-02 5.55153481e-06 5.29246318e-03 5.47011229e-03\n"," 5.47011229e-03 4.60407287e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.76955172e-03\n"," 1.13677945e-01 3.74269117e-01 6.03527889e-01 7.45659671e-01\n"," 7.83369767e-01 7.53156741e-01 6.26258556e-01 3.67564714e-01\n"," 7.32758182e-02 2.98302470e-04 5.29246318e-03 5.47011229e-03\n"," 5.47011229e-03 4.58926877e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.63216770e-03\n"," 1.03192021e-01 3.34848871e-01 5.53238294e-01 6.79458081e-01\n"," 6.59520854e-01 2.70600126e-01 2.13677279e-01 1.95747857e-01\n"," 5.40584403e-02 2.72025205e-04 5.28506113e-03 5.47751434e-03\n"," 2.41306713e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.16445089e-03\n"," 9.29805284e-02 3.09787855e-01 5.02815461e-01 5.38820402e-01\n"," 5.85308492e-01 5.12825618e-01 2.78581290e-01 9.28207367e-02\n"," 5.29474856e-02 3.50579423e-04 5.29986523e-03 5.47011229e-03\n"," 3.95269278e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.73875717e-04\n"," 4.58385603e-02 2.00641905e-01 4.11177941e-01 5.16131835e-01\n"," 5.33939863e-01 4.77824117e-01 4.79303416e-01 2.62861379e-01\n"," 5.60731848e-02 3.68806962e-04 5.29246318e-03 5.47011229e-03\n"," 4.91495881e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.97869247e-03\n"," 8.85744602e-02 3.52690857e-01 5.54867854e-01 6.25462929e-01\n"," 6.38614515e-01 6.35209666e-01 6.20458590e-01 3.49425999e-01\n"," 7.30323834e-02 5.03709258e-04 5.29986523e-03 5.47011229e-03\n"," 5.47011229e-03 4.15254803e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.35272398e-03\n"," 9.44042195e-02 3.36385629e-01 5.49051974e-01 6.83116265e-01\n"," 7.02151923e-01 4.42970008e-01 1.65016689e-01 9.17587281e-02\n"," 2.25081427e-02 2.35014973e-04 5.24805090e-03 5.44050411e-03\n"," 3.76764162e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 4.08963064e-04\n"," 1.99910768e-02 1.13101789e-01 2.56592494e-01 1.64560630e-01\n"," 2.87631773e-01 2.68551703e-01 2.03616233e-01 9.49970309e-02\n"," 2.27559262e-02 0.00000000e+00 5.24805090e-03 7.92018966e-04\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.35014973e-04\n"," 2.36937655e-02 1.24275825e-01 2.01831692e-01 2.18297452e-01\n"," 3.81107961e-01 3.60010278e-01 1.75877341e-01 1.22747580e-01\n"," 4.72798312e-02 0.00000000e+00 5.24805090e-03 3.53077614e-03\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 8.34395681e-04\n"," 7.66962113e-02 2.97779331e-01 5.14192499e-01 6.66636904e-01\n"," 7.03168594e-01 6.58132323e-01 5.29637331e-01 2.88826833e-01\n"," 6.00021910e-02 2.34459820e-04 5.24805090e-03 5.44050411e-03\n"," 5.44050411e-03 1.54702770e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 4.44122784e-04 2.02532018e-02 4.39206900e-02\n"," 1.19672585e-02 3.82269434e-03 1.30732260e-01 1.32480346e-01\n"," 2.94196185e-02 2.41214187e-04 1.38418268e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 7.58802282e-04\n"," 8.15402955e-02 3.26118065e-01 5.79778701e-01 7.69429770e-01\n"," 8.20013968e-01 7.81039880e-01 6.55665961e-01 3.75448541e-01\n"," 7.89216366e-02 4.44307836e-04 5.25545295e-03 5.44050411e-03\n"," 5.44050411e-03 3.98970301e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 9.01661778e-04\n"," 8.88519445e-02 3.59666545e-01 6.06539875e-01 7.81339571e-01\n"," 8.25591687e-01 7.85775247e-01 6.65577671e-01 3.84156771e-01\n"," 8.21202459e-02 5.12036560e-04 5.25545295e-03 5.44050411e-03\n"," 5.44050411e-03 4.87794858e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 4.01468492e-04\n"," 8.63062882e-02 3.52943637e-01 5.88634139e-01 7.59546558e-01\n"," 8.10041838e-01 7.69010074e-01 6.48965074e-01 3.72223932e-01\n"," 8.08737413e-02 5.20548914e-04 5.25545295e-03 5.44050411e-03\n"," 5.44050411e-03 4.75951584e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 4.45325617e-04\n"," 8.25625181e-02 3.32599390e-01 5.59136614e-01 7.18557819e-01\n"," 7.29548192e-01 7.31952192e-01 6.26512446e-01 3.54505283e-01\n"," 7.55422323e-02 6.15665210e-04 5.24805090e-03 5.44050411e-03\n"," 5.44050411e-03 3.63440479e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 1.77428903e-02 1.44211387e-01 2.89856643e-01 3.14884442e-01\n"," 6.37494030e-01 7.26608562e-01 6.03831003e-01 3.50845156e-01\n"," 7.70657585e-02 8.74644309e-04 5.26285500e-03 5.45530820e-03\n"," 4.90015472e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.96081856e-04\n"," 8.08532006e-02 3.48785444e-01 5.76354329e-01 7.44534838e-01\n"," 7.96929020e-01 7.43133908e-01 6.17240735e-01 3.53748146e-01\n"," 6.73492772e-02 5.61075118e-04 5.27765909e-03 5.45530820e-03\n"," 5.46271025e-03 3.96009483e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.83055902e-04\n"," 7.29316230e-02 3.11552133e-01 5.32347313e-01 6.99314071e-01\n"," 7.48349853e-01 7.25717911e-01 6.08816281e-01 3.48216412e-01\n"," 7.41907111e-02 8.34580732e-04 5.27025704e-03 5.46271025e-03\n"," 5.45530820e-03 3.33092088e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.33164462e-04\n"," 6.47524543e-02 2.79683178e-01 4.39994756e-01 6.13629647e-01\n"," 6.94698802e-01 6.60418723e-01 4.99439110e-01 2.46515070e-01\n"," 6.51186705e-02 1.01926179e-03 5.25545295e-03 5.45530820e-03\n"," 5.45530820e-03 1.02148240e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 9.62266033e-05\n"," 5.36898184e-02 1.81042860e-01 3.86564934e-01 4.52013921e-01\n"," 4.44990397e-01 4.01160289e-01 4.99455302e-01 2.88165738e-01\n"," 5.83198909e-02 6.91628711e-04 5.25545295e-03 5.45530820e-03\n"," 1.79869728e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 1.83411607e-02 4.92362846e-02 1.36531024e-01 4.03078715e-01\n"," 3.86278568e-01 2.18663483e-01 1.29585591e-01 6.52511672e-02\n"," 1.86758257e-02 3.33092088e-06 5.26285500e-03 2.02816072e-03\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 5.66846863e-02 2.38072019e-01 4.43515354e-01 6.08878551e-01\n"," 7.74901641e-01 7.08106129e-01 6.05757478e-01 3.38839685e-01\n"," 7.71284908e-02 1.18025630e-03 5.25545295e-03 5.46271025e-03\n"," 5.45530820e-03 9.54863986e-04 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.40494135e-04\n"," 6.79355193e-02 3.00345713e-01 5.33445869e-01 7.44256613e-01\n"," 8.05567764e-01 7.77094775e-01 6.58527685e-01 3.89626883e-01\n"," 8.88906201e-02 1.19950162e-03 5.27025704e-03 5.45530820e-03\n"," 5.45530820e-03 3.30871474e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 5.42408082e-02 2.00231092e-01 3.50636234e-01 5.62251673e-01\n"," 6.37107643e-01 5.59950377e-01 4.74063785e-01 3.11606538e-01\n"," 7.87140092e-02 6.60262539e-04 5.25545295e-03 5.45530820e-03\n"," 4.13034189e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 5.57325056e-02 2.70926834e-01 4.69228675e-01 6.20193782e-01\n"," 6.35826996e-01 5.06286836e-01 3.40945752e-01 1.52055243e-01\n"," 3.71004445e-02 2.99967931e-04 5.25545295e-03 5.45530820e-03\n"," 3.27910656e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 5.16611025e-02 2.18366013e-01 4.02826490e-01 6.07269531e-01\n"," 6.83666977e-01 6.68572910e-01 5.61322994e-01 3.37926087e-01\n"," 8.42614728e-02 7.32154915e-04 5.25545295e-03 5.45530820e-03\n"," 5.44050411e-03 3.25690042e-04 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 2.40486011e-02 1.09275486e-01 1.03733759e-01 1.04029563e-01\n"," 6.70050821e-02 6.53950444e-02 8.48896290e-02 4.60782015e-02\n"," 1.63417754e-02 1.11030696e-06 1.93933616e-03 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.29463439e-04\n"," 7.41335303e-02 3.35799572e-01 6.32090536e-01 8.25710583e-01\n"," 8.91081385e-01 8.63204446e-01 7.36226781e-01 4.58052788e-01\n"," 1.14214594e-01 2.19128331e-03 5.25545295e-03 5.46271025e-03\n"," 5.45530820e-03 4.88535063e-03 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n"," 0.00000000e+00 0.00000000e+00 0.00000000e+00 8.88245569e-05\n"," 6.51937088e-02 2.96583808e-01 5.09696496e-01 6.33510619e-01\n"," 7.31043405e-01 5.48872104e-01 3.78946285e-01 2.81175615e-01\n"," 5.11465677e-02 2.00410406e-03 5.27025704e-03 5.46271025e-03\n"," 5.45530820e-03 8.66039430e-04 0.00000000e+00 0.00000000e+00]\n","------------------------------------------------------------------------------------------------------------------------\n","(25560, 7) \n"," (744, 7) \n"," (25560,) \n"," (744,)\n"]}]},{"cell_type":"code","source":["x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],1)\n","#x_val = x_val.reshape(x_val.shape[0],x_val.shape[1],1)\n","x_pred = x_pred.reshape(x_pred.shape[0],x_pred.shape[1],1)\n","\n","#print(x_train.shape,'\\n',x_val.shape,'\\n',x_pred.shape)\n","print(x_train.shape,'\\n',x_pred.shape)\n","\n","feature_num = len(x_train[0])\n","feature_num"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wyaklvMXsOEq","outputId":"ad165e3a-af6c-43a9-c201-951198e1a683"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(25560, 7, 1) \n"," (744, 7, 1)\n"]},{"output_type":"execute_result","data":{"text/plain":["7"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["from tensorflow.keras import models,layers\n","gru= models.Sequential() # 모델\n","gru.add(layers.GRU(units=32,return_sequences=True,  activation='tanh', input_shape=(feature_num,1)))\n","gru.add(layers.Dropout(rate=0.2))\n","gru.add(layers.GRU(units=64,return_sequences=True, activation='tanh'))\n","gru.add(layers.Dropout(rate=0.2))\n","gru.add(layers.GRU(64, activation='tanh')) \n","gru.add(layers.Dropout(rate=0.2))\n","gru.add(layers.Dense(1)) \n","gru.summary()\n","gru.compile(loss='mse', optimizer='adam', metrics=['mae']) \n","\n","from keras.models import Sequential \n","from keras.layers import Dense, SimpleRNN , Dropout\n","rnn = Sequential()\n","rnn.add(layers.SimpleRNN(units=32,return_sequences=True,  activation='tanh', input_shape=(feature_num,1)))\n","rnn.add(layers.Dropout(rate=0.2))\n","rnn.add(layers.SimpleRNN(units=64,return_sequences=True, activation='tanh'))\n","rnn.add(layers.Dropout(rate=0.2))\n","rnn.add(layers.SimpleRNN(64, activation='tanh')) \n","rnn.add(layers.Dropout(rate=0.2))\n","rnn.add(layers.Dense(1)) \n","rnn.summary()\n","rnn.compile(optimizer = 'adam', loss = 'mse' , metrics=['mae'])\n","\n","from tensorflow.keras import models, layers\n","lstm = models.Sequential() # 모델\n","lstm.add(layers.LSTM(units=32,return_sequences=True,  activation='tanh', input_shape=(feature_num,1)))\n","lstm.add(layers.Dropout(rate=0.2))\n","lstm.add(layers.LSTM(units=64,return_sequences=True, activation='tanh'))\n","lstm.add(layers.Dropout(rate=0.2))\n","lstm.add(layers.LSTM(64, activation='tanh')) \n","lstm.add(layers.Dropout(rate=0.2))\n","lstm.add(layers.Dense(1)) \n","lstm.summary()\n","lstm.compile(loss='mse', optimizer='adam', metrics=['mae']) "],"metadata":{"id":"X1eCGxTgKumI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6a434b0e-25a5-49e9-a9a0-3b51b9c04f72"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," gru (GRU)                   (None, 7, 32)             3360      \n","                                                                 \n"," dropout (Dropout)           (None, 7, 32)             0         \n","                                                                 \n"," gru_1 (GRU)                 (None, 7, 64)             18816     \n","                                                                 \n"," dropout_1 (Dropout)         (None, 7, 64)             0         \n","                                                                 \n"," gru_2 (GRU)                 (None, 64)                24960     \n","                                                                 \n"," dropout_2 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 47,201\n","Trainable params: 47,201\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," simple_rnn (SimpleRNN)      (None, 7, 32)             1088      \n","                                                                 \n"," dropout_3 (Dropout)         (None, 7, 32)             0         \n","                                                                 \n"," simple_rnn_1 (SimpleRNN)    (None, 7, 64)             6208      \n","                                                                 \n"," dropout_4 (Dropout)         (None, 7, 64)             0         \n","                                                                 \n"," simple_rnn_2 (SimpleRNN)    (None, 64)                8256      \n","                                                                 \n"," dropout_5 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 15,617\n","Trainable params: 15,617\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 7, 32)             4352      \n","                                                                 \n"," dropout_6 (Dropout)         (None, 7, 32)             0         \n","                                                                 \n"," lstm_1 (LSTM)               (None, 7, 64)             24832     \n","                                                                 \n"," dropout_7 (Dropout)         (None, 7, 64)             0         \n","                                                                 \n"," lstm_2 (LSTM)               (None, 64)                33024     \n","                                                                 \n"," dropout_8 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 62,273\n","Trainable params: 62,273\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n","from sklearn.ensemble import VotingRegressor\n","\n","Epoch = 200 #------------------------------------------ 원하는대로 바꿔도 됨.\n","\n","est_gru = KerasRegressor(build_fn=lambda:gru, epochs=Epoch-50, verbose=1, validation_split=0.2)\n","est_gru._estimator_type=\"regressor\"\n","est_rnn = KerasRegressor(build_fn=lambda:rnn, epochs=Epoch, verbose=1, validation_split=0.2)\n","est_rnn._estimator_type=\"regressor\"\n","est_lstm = KerasRegressor(build_fn=lambda:lstm, epochs=Epoch+50, verbose=1, validation_split=0.2)\n","est_lstm._estimator_type=\"regressor\"\n","\n","vote = VotingRegressor(estimators=[('gru', est_gru), ('rnn', est_rnn), ('lstm', est_lstm)])\n","#vote = VotingRegressor(estimators=[('gru', gru), ('rnn', rnn), ('lstm', lstm)])\n","history = vote.fit(x_train,y_train)"],"metadata":{"id":"llJ95yHp8q3A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Vote_Pred = vote.predict(x_pred)"],"metadata":{"id":"aXRuS4CHDJDa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_val = data['전력거래량'].max()\n","Vote_Pred_Rescale = max_val*Vote_Pred\n","print(Vote_Pred_Rescale)"],"metadata":{"id":"n7OjLBnCqwbV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range (0,len(Vote_Pred_Rescale)):\n","  if Vote_Pred_Rescale[i] < 0 :\n","    Vote_Pred_Rescale[i] = 0\n","\n","print(Vote_Pred_Rescale)"],"metadata":{"id":"zfDy82Vjrw22"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# 17520 부터 2020년 data\n","\n","for t in range (0,10): # 10개씩 plot figure 보고싶음\n","  date= t + 20  #-------- 보고싶은 구간 반영하여 0~21 까지 수동으로 더해주기\n","  Ans_date = 25584+date*24 # --- Answer 범위가 range-24부터 시작하니까 (21888부터 20년 7월) (25560부터 20년 12월)\n","  \n","  x=np.array(range(24))\n","  Y = Vote_Pred_Rescale[24*date:24*date+24]\n","  Answer = pd.Series(data[Ans_date-24:Ans_date]['전력거래량']).array\n","  #Answer = pd.Series(data[Ans_date-24:Ans_date]['전력거래량']).array\n","  \n","  plt.figure()\n","  plt.plot(x,Y,'bo:')\n","  plt.plot(x,Answer,'r*-')\n","  plt.legend(['Vote','Real'])"],"metadata":{"id":"wX2Id0PDGQSG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import mean_absolute_error\n","\n","voting_mae = mean_absolute_error(vote.predict(x_pred), y_pred)\n","print('Voting Regressor mae :', max_val*voting_mae)"],"metadata":{"id":"fuRUk380snA1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"iIvR4YFaVxNT"},"execution_count":null,"outputs":[]}]}